% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/torch_linear_reg-fit.R
\name{torch_linear_reg}
\alias{torch_linear_reg}
\alias{torch_linear_reg.default}
\alias{torch_linear_reg.data.frame}
\alias{torch_linear_reg.matrix}
\alias{torch_linear_reg.formula}
\alias{torch_linear_reg.recipe}
\title{Fit a linear regression using torch}
\usage{
torch_linear_reg(x, ...)

\method{torch_linear_reg}{default}(x, ...)

\method{torch_linear_reg}{data.frame}(
  x,
  y,
  epochs = 100L,
  penalty = 0,
  validation = 0,
  learning_rate = 0.1,
  batch_size = NULL,
  conv_crit = -Inf,
  verbose = FALSE,
  ...
)

\method{torch_linear_reg}{matrix}(
  x,
  y,
  epochs = 100L,
  penalty = 0,
  validation = 0,
  learning_rate = 0.1,
  batch_size = NULL,
  conv_crit = -Inf,
  verbose = FALSE,
  ...
)

\method{torch_linear_reg}{formula}(
  formula,
  data,
  epochs = 100L,
  penalty = 0,
  validation = 0,
  learning_rate = 0.1,
  batch_size = NULL,
  conv_crit = -Inf,
  verbose = FALSE,
  ...
)

\method{torch_linear_reg}{recipe}(
  x,
  data,
  epochs = 100L,
  penalty = 0,
  validation = 0,
  learning_rate = 0.1,
  batch_size = NULL,
  conv_crit = -Inf,
  verbose = FALSE,
  ...
)
}
\arguments{
\item{x}{Depending on the context:
\itemize{
\item A \strong{data frame} of predictors.
\item A \strong{matrix} of predictors.
\item A \strong{recipe} specifying a set of preprocessing steps
created from \code{\link[recipes:recipe]{recipes::recipe()}}.
}

The predictor data should be standardized (e.g. centered or scaled).}

\item{...}{Not currently used, but required for extensibility.}

\item{y}{When \code{x} is a \strong{data frame} or \strong{matrix}, \code{y} is the outcome
specified as:
\itemize{
\item A \strong{data frame} with 1 numeric column.
\item A \strong{matrix} with 1 numeric column.
\item A numeric \strong{vector}.
}}

\item{epochs}{An integer for the number of epochs of training.}

\item{penalty}{The amount of weight decay (i.e., L2 regularization).}

\item{validation}{The proportion of the data randomly assigned to a
validation set.}

\item{learning_rate}{A positive number (usually less than 0.1).}

\item{batch_size}{An integer for the number of training set points in each
batch.}

\item{conv_crit}{A non-negative number for convergence.}

\item{verbose}{A logical that prints out the iteration history.}

\item{formula}{A formula specifying the outcome terms on the left-hand side,
and the predictor terms on the right-hand side.}

\item{data}{When a \strong{recipe} or \strong{formula} is used, \code{data} is specified as:
\itemize{
\item A \strong{data frame} containing both the predictors and the outcome.
}}
}
\value{
A \code{torch_linear_reg} object with elements:
\itemize{
\item \code{models}: a list object of serialized models for each epoch.
\item \code{loss}: A vector of loss values (MSE) at each epoch.
\item \code{dim}: A list of data dimensions.
\item \code{parameters}: A list of some tuning parameter values.
\item \code{blueprint}: The \code{hardhat} blueprint data.
}
}
\description{
\code{torch_linear_reg()} fits a model.
}
\details{
The predictors data should all be numeric and encoded in the same units (e.g.
standardized to the same range or distribution). If there are factor
predictors, use a recipe or formula to create indicator variables (or some
other method) to make them numeric.

If \code{conv_crit} is used, it stops training when the difference in the loss
function is below \code{conv_crit} or if it gets worse. The default trains the
model over the specified number of epochs.
}
\examples{
\donttest{
if (torch::torch_is_installed()) {

 ## -----------------------------------------------------------------------------

 set.seed(122)
 in_train <- sample(1:nrow(mtcars), 25)
 mtcars_train <- mtcars[ in_train,]
 mtcars_test  <- mtcars[-in_train,]


 # Using matrices
 set.seed(1)
 torch_linear_reg(x = scale(as.matrix(mtcars_train[, -1])),
                  y = mtcars_train$mpg,
                  epochs = 100, batch_size = 10)

 # Using recipe
 library(recipes)

 mtcars_rec <-
  recipe(mpg ~ ., data = mtcars_train) \%>\%
  step_normalize(all_predictors())

 set.seed(1)
 fit <- torch_linear_reg(mtcars_rec, data = mtcars_train,
                         epochs = 100, batch_size = 20, penalty = 0.01)
 fit

 autoplot(fit)

 predict(fit, mtcars_test)
 }

}
}
